# Расчет требований к Kubernetes кластеру

## Описание проекта

Проект состоит из следующих компонентов:

- **База данных** (PostgreSQL) - отказоустойчивая конфигурация
- **Система кеширования** (Redis) - отказоустойчивая конфигурация
- **Frontend** - статический контент
- **Backend** - бизнес-логика приложения

Приложение упаковывается в Helm Chart для деплоя в различные окружения (dev, staging, production).

---

## Шаг 1: Расчет ресурсов приложения

### Требования компонентов

| Компонент            | CPU (на копию) | RAM (на копию) | Количество копий | Итого CPU   | Итого RAM    |
| -------------------- | -------------- | -------------- | ---------------- | ----------- | ------------ |
| PostgreSQL (БД)      | 1 ядро         | 4 ГБ           | 3                | **3 ядра**  | **12 ГБ**    |
| Redis (Кеш)          | 1 ядро         | 4 ГБ           | 3                | **3 ядра**  | **12 ГБ**    |
| Frontend             | 0.2 ядра       | 50 МБ          | 5                | **1 ядро**  | **0.25 ГБ**  |
| Backend              | 1 ядро         | 600 МБ         | 10               | **10 ядер** | **6 ГБ**     |
| **ИТОГО приложение** | -              | -              | **21 Pod**       | **17 CPU**  | **30.25 ГБ** |

### Обоснование количества копий

**PostgreSQL и Redis (по 3 копии):**

- Обеспечение отказоустойчивости (High Availability)
- Возможность переживания выхода из строя 1 реплики
- Для PostgreSQL: возможна конфигурация Primary + 2 Replica
- Для Redis: возможна конфигурация Master-Slave или Redis Sentinel

**Frontend (5 копий):**

- Распределение нагрузки от внешних пользователей
- Быстрая обработка запросов на отдачу статики
- Возможность обновлений без downtime

**Backend (10 копий):**

- Основная нагрузка по обработке бизнес-логики
- Горизонтальное масштабирование под высокую нагрузку
- Обеспечение отказоустойчивости критичного компонента

---

## Шаг 2: Архитектура Kubernetes кластера

Кластер состоит из двух типов нод:

### Control Plane ноды

- **Назначение:** управление кластером
- **Компоненты:** kube-apiserver, etcd, kube-scheduler, kube-controller-manager
- **Особенность:** пользовательские приложения НЕ размещаются на этих нодах

### Worker ноды

- **Назначение:** запуск контейнеров приложений
- **Компоненты:** kubelet, kube-proxy, container runtime
- **Особенность:** здесь работают все Pod'ы приложения

---

## Шаг 3: Расчет Worker-нод

### Служебные ресурсы на одной Worker-ноде

| Компонент                   | CPU         | RAM          | Назначение                      |
| --------------------------- | ----------- | ------------ | ------------------------------- |
| kubelet                     | 0.1         | 200 МБ       | Агент Kubernetes на ноде        |
| kube-proxy                  | 0.05        | 100 МБ       | Сетевой прокси для Services     |
| Container runtime           | 0.1         | 300 МБ       | Containerd/Docker               |
| CNI плагин                  | 0.1         | 200 МБ       | Сетевая связность между Pod'ами |
| Системные процессы ОС       | 0.15        | 200 МБ       | SSH, monitoring agents и др.    |
| **Итого служебные ресурсы** | **0.5 CPU** | **1 ГБ RAM** |

### Выбор размера ноды

**Конфигурация:** 8 CPU, 24 ГБ RAM

**Доступно для приложений:**

- CPU: 8 - 0.5 = **7.5 CPU**
- RAM: 24 - 1 = **23 ГБ**

**С учетом 75% безопасного использования:**

- CPU: 7.5 × 0.75 = **5.625 CPU**
- RAM: 23 × 0.75 = **17.25 ГБ**

> **Почему 75%, а не 100%?**
>
> - Всплески нагрузки приложений
> - Rolling updates (временно работают старая и новая версия)
> - Эвакуация Pod'ов при обслуживании нод
> - Буфер для системных процессов

### Расчет количества нод

**Минимально необходимо:**

- По CPU: 17 ÷ 5.625 = 3.02 → **4 ноды**
- По RAM: 30.25 ÷ 17.25 = 1.75 → **2 ноды**

**Лимитирующий фактор:** CPU

**Базовая потребность:** 4 ноды

---

## Шаг 4: Отказоустойчивость (N+1)

### Принцип N+1 Redundancy

Для обеспечения отказоустойчивости добавляем запас на выход из строя **минимум одной ноды**.

**Расчет:** 4 (базовая потребность) + 1 = **5 Worker-нод**

### Проверка при падении одной ноды

**Сценарий:** из 5 нод работает 4

**Доступные ресурсы на 4 нодах:**

- CPU: 4 × 5.625 = **22.5 CPU** (требуется 17, запас **5.5 CPU** ✅)
- RAM: 4 × 17.25 = **69 ГБ** (требуется 30.25, запас **38.75 ГБ** ✅)

**Процент использования после падения ноды:**

- CPU: 17 / 22.5 = **75.5%** ✅ (в пределах безопасной нормы)
- RAM: 30.25 / 69 = **43.8%** ✅ (отличный запас для всплесков нагрузки)

### Размещение отказоустойчивых компонентов

Для PostgreSQL и Redis необходимо использовать **Pod Anti-Affinity**, чтобы реплики размещались на **разных нодах**:

```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app: postgres
        topologyKey: kubernetes.io/hostname
```

**Результат:** при падении одной ноды не потеряем все реплики БД/кеша одновременно.

---

## Шаг 5: Расчет Control Plane нод

### Компоненты Control Plane

| Компонент               | CPU       | RAM          | Назначение                           |
| ----------------------- | --------- | ------------ | ------------------------------------ |
| kube-apiserver          | 0.5       | 2 ГБ         | REST API для управления кластером    |
| etcd                    | 0.5       | 4 ГБ         | Распределенная БД состояния кластера |
| kube-scheduler          | 0.2       | 500 МБ       | Размещение Pod'ов на нодах           |
| kube-controller-manager | 0.3       | 500 МБ       | Контроллеры состояния ресурсов       |
| Системные процессы ОС   | 0.2       | 500 МБ       | SSH, monitoring и др.                |
| Запас                   | 0.3       | 500 МБ       | Резерв для пиковых нагрузок          |
| **Итого на ноду**       | **2 CPU** | **8 ГБ RAM** |

### Количество Control Plane нод

**Выбрано:** 3 ноды

**Обоснование:**

- **etcd требует кворума** (большинства) для работы по алгоритму Raft
- При 3 нодах: кворум = 2, можно пережить падение **1 ноды** ✅
- **Нечетное количество** - стандарт для distributed consensus систем
- Альтернативы: 1 нода (нет HA ❌), 5 нод (переживет 2 ноды, но дороже)

### Размер etcd для данного кластера

**Параметры кластера:**

- 5 Worker нод
- ~30 Pod'ов (21 приложение + системные)
- Размер: малый/средний кластер

**Выделено для etcd:** 4 ГБ RAM (достаточно для хранения состояния кластера)

---

## Шаг 6: Системные компоненты кластера

Помимо приложения, в кластере работают обязательные системные Pod'ы:

| Компонент                   | Реплик | CPU (на реплику) | RAM (на реплику) | Итого CPU     | Итого RAM     |
| --------------------------- | ------ | ---------------- | ---------------- | ------------- | ------------- |
| CNI Plugin (на каждой ноде) | 5      | 0.1              | 200 МБ           | 0.5           | 1 ГБ          |
| CoreDNS                     | 2      | 0.1              | 200 МБ           | 0.2           | 0.4 ГБ        |
| Ingress Controller          | 3      | 0.5              | 500 МБ           | 1.5           | 1.5 ГБ        |
| Metrics Server              | 1      | 0.05             | 100 МБ           | 0.05          | 0.1 ГБ        |
| **Итого системные Pod'ы**   | -      | -                | -                | **~2.25 CPU** | **~3 ГБ RAM** |

> **Примечание:** Эти ресурсы уже учтены в служебных 0.5 CPU / 1 ГБ на ноду и в коэффициенте 75% использования.

---

## Итоговая конфигурация кластера

### Worker ноды

| Параметр                                | Значение                       |
| --------------------------------------- | ------------------------------ |
| **Количество нод**                      | 5                              |
| **CPU на ноду**                         | 8 ядер                         |
| **RAM на ноду**                         | 24 ГБ                          |
| **Итого CPU**                           | 40 ядер                        |
| **Итого RAM**                           | 120 ГБ                         |
| **Отказоустойчивость**                  | N+1 (переживет падение 1 ноды) |
| **Использование при нормальной работе** | CPU: ~60%, RAM: ~26%           |
| **Использование при падении 1 ноды**    | CPU: ~75%, RAM: ~44%           |

### Control Plane ноды

| Параметр               | Значение                                       |
| ---------------------- | ---------------------------------------------- |
| **Количество нод**     | 3                                              |
| **CPU на ноду**        | 2 ядра                                         |
| **RAM на ноду**        | 8 ГБ                                           |
| **Итого CPU**          | 6 ядер                                         |
| **Итого RAM**          | 24 ГБ                                          |
| **Отказоустойчивость** | Кворум etcd: 2 из 3 (переживет падение 1 ноды) |

### Общая конфигурация кластера

| Тип ноды          | Количество | CPU (на ноду) | RAM (на ноду) | Итого CPU   | Итого RAM  |
| ----------------- | ---------- | ------------- | ------------- | ----------- | ---------- |
| **Control Plane** | 3          | 2 ядра        | 8 ГБ          | 6 ядер      | 24 ГБ      |
| **Worker**        | 5          | 8 ядер        | 24 ГБ         | 40 ядер     | 120 ГБ     |
| **ИТОГО КЛАСТЕР** | **8 нод**  | -             | -             | **46 ядер** | **144 ГБ** |

---

## Дополнительные рекомендации для Production

### 1. Resource Requests и Limits

В Helm Chart для каждого компонента необходимо явно указывать ресурсы:

```yaml
resources:
  requests: # Гарантированные ресурсы (для Scheduler)
    cpu: "1000m"
    memory: "4Gi"
  limits: # Максимальный лимит (защита от утечек)
    cpu: "1500m"
    memory: "4Gi"
```

**Для БД и кеша:** `requests = limits` (Guaranteed QoS класс)  
**Для frontend/backend:** `requests < limits` (Burstable QoS класс)

### 2. Хранилище (Storage)

**PostgreSQL:**

- StorageClass: SSD (высокий IOPS)
- Размер: 100 ГБ на реплику (минимум)
- Backup: снапшоты через Velero или pg_basebackup

**Redis:**

- Если кеш: emptyDir (без персистентности)
- Если нужна персистентность: SSD, 10-20 ГБ, RDB/AOF снапшоты

### 3. Networking

**Ingress Controller:**

- NGINX Ingress или Traefik
- 2-3 реплики для HA
- Размещение на edge-нодах (опционально)

**Network Policies:**

- Ограничение трафика между namespace
- Запрет прямого доступа к БД извне

### 4. Мониторинг и алертинг

**Обязательные метрики:**

- CPU/RAM utilization нод (алерт при > 80%)
- Disk I/O и latency для БД
- Доступность критичных Pod'ов

**Рекомендуемый стек:**

- Prometheus + Grafana (метрики)
- Loki или ELK (логи)
- AlertManager (уведомления)

### 5. Backup и Disaster Recovery

**Стратегия бэкапов:**

- etcd: ежедневные снапшоты (автоматизация через cronjob)
- PostgreSQL: continuous WAL archiving + periodic snapshots
- Конфигурация кластера: GitOps подход (ArgoCD/Flux)

**RTO/RPO:**

- RTO (Recovery Time Objective): < 1 час
- RPO (Recovery Point Objective): < 15 минут

### 6. Security

**Best practices:**

- RBAC для ограничения доступа к ресурсам
- Pod Security Standards (restricted profile)
- Secrets в зашифрованном виде (Sealed Secrets или External Secrets Operator)
- Regular security scanning (Trivy, Falco)

---

## Обоснование выбора конфигурации

### Почему 8 CPU, 24 ГБ RAM для Worker-нод?

**Альтернативы:**

- 8 CPU, 16 ГБ: впритык по RAM (69% при N-1) ❌
- 8 CPU, 32 ГБ: избыток RAM (35% при N-1), лишние расходы ❌
- **8 CPU, 24 ГБ: оптимальный баланс** ✅

**Преимущества:**

- Достаточный запас RAM (44% при N-1)
- Эффективное использование CPU (75% при N-1)
- Экономия ресурсов по сравнению с 32 ГБ
- Буфер для роста нагрузки

### Почему 5 Worker-нод, а не 4 или 6?

**4 ноды:**

- Нет запаса на отказ ❌
- При падении ноды: перегрузка (использование > 90%)

**6 нод:**

- Избыточный запас (использование < 50%) ❌
- Лишние расходы на инфраструктуру

**5 нод (N+1):**

- Золотая середина ✅
- Комфортный запас при отказе
- Оптимальная стоимость владения

---

## Заключение

Итоговая конфигурация кластера:

- **8 нод:** 3 Control Plane + 5 Worker
- **46 CPU, 144 ГБ RAM** суммарно
- **Отказоустойчивость:** переживет падение 1 ноды любого типа
- **Запас для роста:** ~25% CPU, ~55% RAM при нормальной работе

Конфигурация обеспечивает:
✅ Высокую доступность (HA) всех компонентов  
✅ Запас для пиковых нагрузок и обновлений  
✅ Экономически эффективное использование ресурсов  
✅ Возможность масштабирования при росте нагрузки
